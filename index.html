<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jiacheng Liu Âàò‰Ω≥Êàê</title>
    <link rel="icon" href="images/icons/favicon.png" type="image/png">
    <link rel="stylesheet" href="styles/site.css" type="text/css">
</head>
<body>
    <header>
        <h1><a href="index.html">Jiacheng Liu</a></h1>
        <div class="menu-toggle">‚ò∞</div>
        <nav>
            <ul>
                <li><a href="projects.html">PROJECTS</a></li>
                <li><a href="publications.html">PUBLICATIONS</a></li>
                <li><a href="docs/CV.pdf">CV</a></li>
                <li><a  href="gallery.html">GALLERY</a></li>
                <li><a href="contact.html">CONTACT</a></li>
            </ul>
        </nav>
        <script src="script/script.js"></script>
    </header>
    <main>
        <section class="intro">
            <div class="content">
                <div class="text-container">
                    <h2>üêâ Hi, I'm Jiacheng Liu Âàò‰Ω≥Êàê<br><br></h2>
                    <p>I am a first-year Ph.D. student at the <a href="https://www.scifilab.org/">SciFi Lab</a> at <a href="https://www.cornell.edu/">Cornell University</a>, advised by <a href="https://www.cs.cornell.edu/~zheng/">Prof. Cheng Zhang</a>. My research centers on <b>AI-assisted sensing technologies</b>, with a particular emphasis on <b>wearable form factors</b>. My work focuses on <b>activity-detection systems and assistive devices</b> that provide unobtrusive, seamless monitoring and support.</p><br>

<p>Before Cornell, I earned a Bachelor of Engineering in <a href="https://www.xyc.tsinghua.edu.cn/en/info/1111/1374.htm">Creative Design and Intelligent Engineering</a> (CDIE) at <a href="https://www.xyc.tsinghua.edu.cn/en/">Xinya College</a>, <a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a>. I gained research experience in multiple labs, including the PI Lab and <a href="https://thfl.tsinghua.edu.cn/en/">the Future Lab</a> at Tsinghua University.</p>

                    <div class="links">
                        <div class="link_unit">
                            <a href="https://github.com/Sorrento21" target="_blank">
                                <picture>
                                    <img src="images/icons/github-mark-dark.png" alt="GitHub" />
                                </picture>
                            </a>
                        </div>
                        <div class="link_unit">
                            <a href="https://scholar.google.com/citations?user=_mc1WWgAAAAJ&hl=en" target="_blank">
                                <picture>
                                    <img src="images/icons/google-scholar.png" alt="Google Scholar" />
                                </picture>
                            </a>
                        </div>
                        <div class="link_unit">
                            <a href="https://orcid.org/0009-0007-4525-0352" target="_blank">
                                <picture>
                                    <img src="https://orcid.org/sites/default/files/images/orcid_16x16.png" alt="ORCID iD" />
                                </picture>
                            </a>
                        </div>
                    </div>
                </div>
                <img src="images/style_portrait.jpg" alt="portrait">
            </div>
        </section>

        <section class="interests">
            <div class="content">
                <div class="dot-separator"></div>
                <h2>Research Interests</h2>
                <div class="interest_container">
                    <img src="images/research_interests.png" alt="interests">
                    <p>
                        How can we integrate <b>AI with sensing systems</b> to develop <b>early detection systems and assistive devices</b> for everyday use, providing <b>unobtrusive and seamless</b> health support for individuals with diverse health conditions?
                    </p>
                </div>
            </div>
        </section>

        <section class="updates">
            <div class="content">
                <div class="dot-separator"></div>
                <h2>Updates</h2>
                <div class="news_list">
                    
                    <div class="update">
                        <time datetime="2025-06-20">2025-06-20</time>
                        <p>üèÜ I was awarded the <strong>Outstanding Undergraduate Thesis</strong>.</p>
                    </div>

                    <div class="update">
                        <time datetime="2025-06-20">2025-06-20</time>
                        <p>üèµ I was awarded the <strong>Xinya College Academic Excellence Award</strong>.</p>
                    </div>

                    <div class="update">
                        <time datetime="2025-04-03">2025-04-03</time>
                        <p>üéâ I will be joining the <strong>SciFi Lab at Cornell University</strong> as a Ph.D. student in the Department of Information Science.</p>
                    </div>
                
                    <div class="update">
                        <time datetime="2025-02-01">2025-02-01</time>
                        <p>üì© I have submitted <strong>PPG-based Authentication on Smartwatches in Daily Scenarios</strong> to IMWUT'25 full paper track.</p>
                    </div>
                </div>
            </div>
        </section>
        
        <section class="projects">
            <div class="content">
                <div class="dot-separator"></div>
                <h2>Research Projects</h2>
                <p>* indicates co-first author.</p>

                <div class="display_row">
                    <div class="project">
                        <figure>
                            <img src="images/research/speech.png" alt="speech">
                        </figure>
                        <h3>NeckVoice: Voice Synthesis for Laryngectomees with On-body Sound Actuation</h3>
                        <p class="author">Ruidong Zhang, <u>Jiacheng Liu</u>, Justin Xiang, Ke Li, Babak Sadoughi, Sam Tilsen, Fran√ßois Guimbreti√®re, Cheng Zhang</p>
                        <p class="state">2025, Nat. Mach. Intell. (Ready to submit)</p>
                        <div class="links">
                            <!-- <a href="https://arxiv.org/abs/2404.05003" target="_blank">Paper</a> -->
                            <!-- <a href="link_to_video" target="_blank">Video</a> -->
                            <!-- <a href="https://doi.org/10.48550/arXiv.2404.05003" target="_blank">DOI</a> -->
                        </div>
                    </div>
                    <div class="project">
                        <figure>
                            <img src="images/research/PPG_authen.jpg" alt="ppg_authen">
                        </figure>
                        <h3>Exploring Reliable PPG Authentication on Smartwatches in Daily Scenarios</h3>
                        <p class="author">Jiankai Tang, <u>Jiacheng Liu*</u>, RENLING TONG, Kai Zhu, Zhe Li, Junliang Xing, Yuanchun Shi, Yuntao Wang</p>
                        <p class="state">2025, arXiv'25</p>
                        <div class="links">
                            <a href="docs/_CHI_IMWUT_2025__Robust_and_Efficient_PPG_authentification.pdf" target="_blank">Paper</a>
                            <!-- <a href="link_to_video" target="_blank">Video</a> -->
                            <a href="https://doi.org/10.48550/arXiv.2503.23930" target="_blank">DOI</a>
                        </div>
                    </div>
                    <div class="project">
                        <figure>
                            <img src="images/research/odoragent.png" alt="odoragent">
                        </figure>
                        <h3>OdorAgent: Generate Odor Sequences for Movies Based on Large Language Model</h3>
                        <p class="author">Yu Zhang, Peizhong Gao, Fangzhou Kang, Jiaxiang Li, <u>Jiacheng Liu</u>, Qi Lu, Yingqing Xu</p>
                        <p class="state">2024, IEEE VR'24</p>
                        <div class="links">
                            <a href="docs/OdorAgent_Generate_Odor_Sequences_for_Movies_Based_on_Large_Language_Model.pdf" target="_blank">Paper</a>
                            <!-- <a href="link_to_video" target="_blank">Video</a> -->
                            <a href="https://ieeexplore.ieee.org/abstract/document/10494179" target="_blank">DOI</a>
                        </div>
                    </div>
                </div>

                <div class="display_row">
                    <div class="project">
                        <figure>
                            <img src="images/research/camera.png" alt="camera">
                        </figure>
                        <h3>Camera-Based Remote Physiology Sensing for Hundreds of Subjects Across Skin Tones</h3>
                        <p class="author">Jiankai Tang, Xinyi Li, <u>Jiacheng Liu</u>, Xiyuxing Zhang, Zeyu Wang, Yuntao Wang</p>
                        <p class="state">2024, CHI'24 Workshop PhysioCHI</p>
                        <div class="links">
                            <a href="docs/Camera-Based Remote Physiology Sensing.pdf" target="_blank">Paper</a>
                            <!-- <a href="link_to_video" target="_blank">Video</a> -->
                            <a href="https://doi.org/10.48550/arXiv.2404.05003" target="_blank">DOI</a>
                        </div>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <p>Copyright &copy; 2025 Jiacheng Liu All Rights Reserved.</p>
    </footer>
</body>
</html>